[train] #train parameters
epoch = 1
batch_size = 512

reader_num = 0

learning_rate =  0.0006
weight_decay = 0
step_size = 1
lr_multiplier = 1

[eval] #eval parameters
batch_size = 128
reader_num = 0

[data] #data parameters

train_data_path = /home/dkb/workspace/Code/nlp_data/jieba/valid.json

train_formatter_type = BertFormatter
valid_formatter_type = BertFormatter
test_formatter_type = BertFormatter

max_seq_length = 300

[model] #model parameters
model_name = Bert

bert_path = /home/dkb/workspace/Code/Code/Bert_path
num_classes = 72


src_vocab_path = /home/dkb/workspace/Code/nlp_data/jieba/src_dic
trg_vocab_path = /home/dkb/workspace/Code/nlp_data/jieba/trg_label.dic
eval_vocab_path = /home/dkb/workspace/Code/nlp_data/jieba/trg_label.dic


[output] #output parameters

eval_output = Test_eval
model_path = Test_checkpoint
tensorboard_path = Test_tensorboard

output_time = 10

model_name = Bert

output_function = threshold_onehot
threshold = 0.3
top-k = 3